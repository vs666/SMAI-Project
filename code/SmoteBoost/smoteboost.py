# -*- coding: utf-8 -*-
"""SmoteBoost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19y4c4wKcURkoyi0HnjNW7RA-LGBCCT2Y
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
import numpy as np
import random
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from imblearn.over_sampling import SMOTE
import sys


class SmoteBoost:
  def __init__(self,n_classifiers,base_classifier,learning_rate,supports_class_probabilities=False):
    self.n_classifiers = n_classifiers
    self.algorithm='SAMME'
    if supports_class_probabilities:
      self.algorithm='SAMME.R'
    
    self.classifier = AdaBoostClassifier(base_estimator=base_classifier,n_estimators=self.n_classifiers,learning_rate=learning_rate)
    
  def fit(self,X,y):
    x_final,y_final = SMOTE().fit_resample(X,y.ravel())
    self.classifier.fit(x_final,y_final)
    return self.classifier.score(x_final,y_final)

  def predict(self,x_predict):
    return self.classifier.predict(x_predict)



def makeData(minority_fraction, n_features,n_samples,test_size=0.2):
  X,y = make_classification(n_samples=n_samples,n_features=n_features,n_classes=2,weights=[minority_fraction,1-minority_fraction],random_state=0)
  X_train, X_test, y_train,y_test = train_test_split(X,y, test_size = test_size, random_state = 1)
  return X_train,X_test,y_train,y_test

def getClassifier(classifier_label):
  classifier = DecisionTreeClassifier() # by default
  if classifier_label == 'SVM':
    classifier = SVC(kernel='rbf',probability=True)
  elif classifier_label == 'DecisionTree':
    classifier = DecisionTreeClassifier()
  return classifier

def main(classifier_label,minority_fraction,n_features,n_samples,n_classifiers,test_size=0.2):
  classifier = getClassifier(classifier_label)
  X_train,X_test,y_train,y_test = makeData(minority_fraction,n_features,n_samples,test_size)
  
  classifier = DecisionTreeClassifier()
  model = SmoteBoost(100,classifier,learning_rate=0.1)
  score = model.fit(X_train,y_train)
  print(score)
  y_pred = model.predict(X_test)
  mino = [0,0]
  majo = [0,0]
  for i in range(len(y_test)):
    if y_test[i] == 1 and y_pred[i] == 0:
      majo[0]+=1
    elif y_test[i] == 1 and y_pred[i] == 1:
      majo[1] += 1
    elif y_test[i] == 0 and y_pred[i] == 0:
      mino[0]+=1
    elif y_test[i] == 0 and y_pred[i] == 1:
      mino[1] += 1
  print('Majority Accuracy ',majo[1]/sum(majo)*100)
  print('Minority Accuracy',mino[0]/sum(mino)*100)
  print('Majority',majo)
  print('Minority',mino)


if __name__ == '__main__':
  try:
    classifier_label = sys.argv[1]
    minority_fraction = float(sys.argv[2])
    n_features = int(sys.argv[3]) or 4
    n_samples = int(sys.argv[4]) or 1000 
    n_classifiers = int(sys.argv[5]) or 100
    test_size = float(sys.argv[6]) or 0.2
    main(classifier_label,minority_fraction,n_features,n_samples,n_classifiers,test_size)
  except:
    print("Invalid Input format. Please follow the following format.")
    print("python3 smoteboost.py [Classifier-Label] [Minority-Fraction] [n-features] [n-samples] [n-classifiers] [test-size]")
    print("Classifier-Label : SVM/DecisionTree")
    print("Minority Fraction : float in range (0,0.5) exclusive")
    print("n-features :int  >= 4 (number of features in the dataset")
    print("n-samples :int  (number of samples in the dataset)")
    print("n-classifiers : int (number of classifiers that the AdaBoost algorithm has ")
    print("test-size : float fraction of total data as the test data")
  # Write code here to call main()